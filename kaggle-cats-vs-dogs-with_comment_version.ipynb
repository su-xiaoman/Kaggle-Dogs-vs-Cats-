{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scikit_learn in /root/miniconda3/lib/python3.8/site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /root/miniconda3/lib/python3.8/site-packages (from scikit_learn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /root/miniconda3/lib/python3.8/site-packages (from scikit_learn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /root/miniconda3/lib/python3.8/site-packages (from scikit_learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from scikit_learn) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: xgboost in /root/miniconda3/lib/python3.8/site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy in /root/miniconda3/lib/python3.8/site-packages (from xgboost) (1.8.0)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from xgboost) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Tue May 10 20:56:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   25C    P8    17W / 230W |  23287MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    500767      C                                   23285MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit_learn\n",
    "!pip install xgboost\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.212164,
     "end_time": "2020-10-13T23:14:15.791794",
     "exception": false,
     "start_time": "2020-10-13T23:14:15.579630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 19:22:31.053396: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import gc\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.121175,
     "end_time": "2020-10-13T23:14:16.546959",
     "exception": false,
     "start_time": "2020-10-13T23:14:16.425784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (25000,) test: (12500,) target: (25000,)\n",
      "sampling from test label: [2345, 170, 5378, 11242, 3465]\n"
     ]
    }
   ],
   "source": [
    "#定义读取测试提交格式\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "#定义训练测试文件夹\n",
    "IMG_SIZE = 224\n",
    "TRAIN_FOLDER = 'train/'\n",
    "TEST_FOLDER =  'test/'\n",
    "\n",
    "#定义测试训练，其中.npy是由numpy定义的二进制文件，由np.save()/np.load()读取生成\n",
    "train_image_list = np.load('cats_and_dogs/train_image_list.npy')\n",
    "test_image_list = np.load('cats_and_dogs/test_image_list.npy')\n",
    "target = np.load('cats_and_dogs/target.npy')\n",
    "\n",
    "print(\"train:\",train_image_list.shape,\"test:\",test_image_list.shape,\"target:\",target.shape)\n",
    "\n",
    "\n",
    "#定义sample_submission.csv中与ids相对应的测试标签\n",
    "ids = [int(x.split('.')[0]) for x in test_image_list]\n",
    "print(\"sampling from test label:\",ids[:5])\n",
    "\n",
    "#已经预制模型以标签\n",
    "train_EB7_ns = np.load('cats_and_dogs/train_EB7_ns.npy')\n",
    "test_EB7_ns = np.load('cats_and_dogs/test_EB7_ns.npy')\n",
    "train_EB4_ns = np.load('cats_and_dogs/train_EB4_ns.npy')\n",
    "test_EB4_ns = np.load('cats_and_dogs/test_EB4_ns.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 硬件配置\n",
    "- CPU： AMD EPYC 7543 32-Core Processor-15核\n",
    "- 内存：80GB\n",
    "- GPU： RTX A5000*1-24GB\n",
    "\n",
    "## 模型使用说明\n",
    "- 本模型基于三个主要的预测工具，xgboost/logistic_regression/1-MLP的nn,其中每一个都是由train_EB7_ns和train_EB4_ns分别延伸出来\n",
    "- train_EB7_ns和train_EB4_ns所推导出来的特征向量个数并不一样，其中train_EB7_ns.shape=(25000, 2560),train_EB4_ns.shape=(25000, 1792)\n",
    "- 为了更好的成绩，以下的模型均使用了梯度裁减，其裁减方式包括两种：**1.**将处于分布边缘的数据归0和1  **2.**直接保留中间数值，其保留标准为占有大概11000左右的数据\n",
    "- 应该将EB7和EB4分开训练，不然显存会爆掉，出现Memory allocation error on worker 0: Caching allocator错误\n",
    "- 最好引入python-gc(garbage collect)，否则会出现显存溢出的错误\n",
    "\n",
    "## 结果说明\n",
    "- 在使用单一预测方式时，最好的成绩表现为0.03000左右，nn>xgboost>lr\n",
    "- 最好的成绩出现在xgboost+lr的组合方式上，经过比例调节，能够保持在0.0298左右，但是无法继续下降\n",
    "- 任何包括了传统神经网络nn结构的组合都会降低其准确率，包括已经试验的xgboost+nn双组合/xgboost+nn+lr三模型组合\n",
    "- 在验证集上，借助sklearn.metrics.roc_auc_score，预训练特征向量能够维持在5个9，而借助tensorflow_hub与自己训练组合出来的特征向量大概在3个9，不清楚原始作者使用了哪些优化手段。 借助sklearn.metrics.logloss(和kaggle检测方式一样）,神经网络在单一预测中拥有明显优势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.2633,
     "end_time": "2020-10-13T23:14:19.867113",
     "exception": false,
     "start_time": "2020-10-13T23:14:19.603813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2560)\n"
     ]
    }
   ],
   "source": [
    "print(train_EB7_ns.shape)\n",
    "EB7_X_train, EB7_X_val, EB7_y_train, EB7_y_val = train_test_split(train_EB7_ns, \n",
    "                                                                  target, \n",
    "                                                                  test_size=0.1, \n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型EB7的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 19:23:08.015152: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-10 19:23:08.017213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-05-10 19:23:08.017256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-10 19:23:08.029429: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-10 19:23:08.029504: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-10 19:23:08.035060: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-10 19:23:08.037663: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-10 19:23:08.040081: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-05-10 19:23:08.042683: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-10 19:23:08.042871: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-10 19:23:08.044608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-10 19:23:08.045545: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-10 19:23:08.054156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-05-10 19:23:08.054995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-10 19:23:08.055543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-10 19:23:08.787923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-10 19:23:08.787962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-05-10 19:23:08.787970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-05-10 19:23:08.789835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21250 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:41:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "#调用神经网络\n",
    "input_tensor = Input(EB7_X_train.shape[1:])\n",
    "x = input_tensor\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LayerNormalization()(x)\n",
    "x = Dropout(0.5)(x) \n",
    "# x = Dense(1024,activation='relu',kernel_regularizer=keras.regularizers.l2(1e-3))(x) #加上一层全连接并不能加大准确率\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(1,activation='sigmoid')(x) \n",
    "#in Model(first_layer,last_layer)    \n",
    "model1 = Model(input_tensor, x)\n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=['binary_accuracy'],\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 256\n",
    "print(\"------model1 training-----------\")\n",
    "model1.fit(EB7_X_train, EB7_y_train,batch_size=batch_size,epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------model1 evaluating-----\n",
      "\n",
      "0.9999737598488568\n",
      "0.008180712779016221\n",
      "(12500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"---------model1 evaluating-----\\n\")\n",
    "nn_pred1 = model1.predict(EB7_X_val)\n",
    "print(roc_auc_score(EB7_y_val, nn_pred1))\n",
    "print(log_loss(EB7_y_val, nn_pred1))\n",
    "\n",
    "\n",
    "# 0.9999718398377975\n",
    "# 0.008397303281173026\n",
    "\n",
    "test_preds_nn1 = model1.predict(test_EB7_ns)\n",
    "print(test_preds_nn1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 2.176653,
     "end_time": "2020-10-13T23:14:22.228257",
     "exception": false,
     "start_time": "2020-10-13T23:14:20.051604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n",
      "0.999992319955763\n",
      "0.008745738095360568\n"
     ]
    }
   ],
   "source": [
    "#调用模型logistic回归\n",
    "EB7_lr = LogisticRegression(C=0.026, max_iter=10000)\n",
    "EB7_lr.fit(EB7_X_train, EB7_y_train)\n",
    "val_preds_EB7_lr = EB7_lr.predict_proba(EB7_X_val)[:,1]\n",
    "\n",
    "test_preds_EB7_lr = EB7_lr.predict_proba(test_EB7_ns)[:,1]\n",
    "print(test_preds_EB7_lr.shape)\n",
    "\n",
    "print(roc_auc_score(EB7_y_val, val_preds_EB7_lr))\n",
    "print(log_loss(EB7_y_val, val_preds_EB7_lr))\n",
    "\n",
    "# (12500,)\n",
    "# 0.999992319955763\n",
    "# 0.008745738095360568\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 1.981048,
     "end_time": "2020-10-13T23:14:24.332561",
     "exception": false,
     "start_time": "2020-10-13T23:14:22.351513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义xgb参数并构造训练样本\n",
    "xgb_params1 = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'alpha': 0.01,\n",
    "    'lambda': 1.00,\n",
    "    'gamma' : 0.02,\n",
    "    'max_bin': 256,\n",
    "    'objective': 'reg:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 0,\n",
    "    'tree_method': 'gpu_hist', \n",
    "    'predictor': 'gpu_predictor'\n",
    "}\n",
    "dtrain1 = xgb.DMatrix(EB7_X_train, EB7_y_train)\n",
    "dval1 = xgb.DMatrix(EB7_X_val, EB7_y_val)\n",
    "dtest1 = xgb.DMatrix(test_EB7_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n",
      "0.999992319955763\n",
      "0.008210439385659993\n",
      "0.9999916799520766\n",
      "0.008179385205861714\n"
     ]
    }
   ],
   "source": [
    "# 模型xgboost训练并预测\n",
    "model = xgb.train(xgb_params1, dtrain1, num_boost_round=100)\n",
    "val_preds_xgb_1 = model.predict(dval1)\n",
    "test_preds_xgb_1 = model.predict(dtest1)\n",
    "print(test_preds_xgb_1.shape)\n",
    "\n",
    "#输出指标\n",
    "#使用非加权的结果\n",
    "print(roc_auc_score(EB7_y_val, val_preds_xgb_1))\n",
    "print(log_loss(EB7_y_val, val_preds_xgb_1))\n",
    "#使用加权的测试\n",
    "print(roc_auc_score(EB7_y_val, 0.5*val_preds_xgb_1+0.5*val_preds_EB7_lr))\n",
    "print(log_loss(EB7_y_val, 0.5*val_preds_xgb_1+0.5*val_preds_EB7_lr))\n",
    "\n",
    "# (12500,)\n",
    "# 0.999992319955763\n",
    "# 0.008210439385659993\n",
    "# 0.9999916799520766\n",
    "# 0.008179385205861714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2599"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#清除已经用过的EB7模型，不然会导致显存爆掉，在RTX A5000 * 1-显存:24GB下依然会爆掉\n",
    "del train_EB7_ns, test_EB7_ns, EB7_X_train, EB7_X_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 1792)\n"
     ]
    }
   ],
   "source": [
    "EB4_X_train, EB4_X_val, EB4_y_train, EB4_y_val = train_test_split(train_EB4_ns, \n",
    "                                                                  target, \n",
    "                                                                  test_size=0.1, \n",
    "                                                                  random_state=42)\n",
    "print(test_EB4_ns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型EB4的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#神经网络模型\n",
    "input_tensor = Input(EB4_X_train.shape[1:])\n",
    "x = input_tensor\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LayerNormalization()(x)\n",
    "x = Dropout(0.5)(x) \n",
    "# x = Dense(1024,activation='relu',kernel_regularizer=keras.regularizers.l2(1e-3))(x) #加上一层全连接并不能加大准确率\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(1,activation='sigmoid')(x) \n",
    "#in Model(first_layer,last_layer)    \n",
    "model2 = Model(input_tensor, x)\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=['binary_accuracy'],\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------model2-----------\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9502\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9971\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9972\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9973\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9976\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f589c68c790>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"------model2-----------\")    \n",
    "model2.fit(EB4_X_train, EB4_y_train, batch_size=batch_size,epochs=10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------model2-----\n",
      "\n",
      "(2500, 1)\n",
      "0.9999628797861876\n",
      "0.010230590942026356\n",
      "(12500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"---------model2-----\\n\")\n",
    "nn_pred2 = model2.predict(EB4_X_val)\n",
    "print(nn_pred2.shape)\n",
    "print(roc_auc_score(EB4_y_val, nn_pred2))\n",
    "print(log_loss(EB4_y_val, nn_pred2))\n",
    "\n",
    "\n",
    "test_preds_nn2 = model2.predict(test_EB4_ns)\n",
    "print(test_preds_nn2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n",
      "0.9999948799705086\n",
      "0.009172899469261296\n"
     ]
    }
   ],
   "source": [
    "#逻辑回归模型\n",
    "EB4_lr = LogisticRegression(C=0.019, max_iter=10000)\n",
    "EB4_lr.fit(EB4_X_train, EB4_y_train)\n",
    "val_preds_EB4_lr = EB4_lr.predict_proba(EB4_X_val)[:,1]\n",
    "\n",
    "test_preds_EB4_lr = EB4_lr.predict_proba(test_EB4_ns)[:,1]\n",
    "print(test_preds_EB4_lr.shape)\n",
    "\n",
    "print(roc_auc_score(EB4_y_val, val_preds_EB4_lr))\n",
    "print(log_loss(EB4_y_val, val_preds_EB4_lr))\n",
    "\n",
    "#(12500,)\n",
    "# 0.9999948799705086\n",
    "# 0.009172899469261296\n",
    "#\n",
    "# 0.9999577597566962\n",
    "# 0.011528056949842722\n",
    "# 0.9999897599410172\n",
    "# 0.009885062067780902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 2.96171,
     "end_time": "2020-10-13T23:14:27.784038",
     "exception": false,
     "start_time": "2020-10-13T23:14:24.822328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#xgboost模型参数定义\n",
    "xgb_params2 = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'alpha': 0.01,\n",
    "    'lambda': 1.00,\n",
    "    'gamma' : 0.02,\n",
    "    'max_bin': 256,\n",
    "    'objective': 'reg:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 0,\n",
    "    'tree_method': 'gpu_hist', \n",
    "    'predictor': 'gpu_predictor'\n",
    "}\n",
    "\n",
    "\n",
    "dtrain2 = xgb.DMatrix(EB4_X_train, EB4_y_train)\n",
    "dval2 = xgb.DMatrix(EB4_X_val, EB4_y_val)\n",
    "dtest2 = xgb.DMatrix(test_EB4_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999577597566962\n",
      "0.011528056949842722\n",
      "0.9999897599410172\n",
      "0.009885062067780902\n"
     ]
    }
   ],
   "source": [
    "#xgboost 参数模型\n",
    "val_preds_xgb_2 = 0\n",
    "test_preds_xgb_2 = 0\n",
    "\n",
    "n_seed = 10\n",
    "\n",
    "for j in range(n_seed):\n",
    "    xgb_params2['seed'] = 3*j**2+154\n",
    "    model = xgb.train(xgb_params2, dtrain2, num_boost_round=100)\n",
    "    val_preds_xgb_2 += model.predict(dval2)/n_seed\n",
    "    test_preds_xgb_2 += model.predict(dtest2)/n_seed\n",
    "\n",
    "#输出指标\n",
    "#使用非加权的结果\n",
    "print(roc_auc_score(EB4_y_val, val_preds_xgb_2))\n",
    "print(log_loss(EB4_y_val, val_preds_xgb_2))\n",
    "#使用加权的测试\n",
    "print(roc_auc_score(EB4_y_val, 0.5*val_preds_xgb_2+0.5*val_preds_EB4_lr))\n",
    "print(log_loss(EB4_y_val, 0.5*val_preds_xgb_2+0.5*val_preds_EB4_lr))\n",
    "\n",
    "#0.9999577597566962\n",
    "# 0.011528056949842722\n",
    "# 0.9999897599410172\n",
    "# 0.009885062067780902"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看三种模型的形状以便于组合集成\n",
    "print(test_preds_xgb_1.shape)\n",
    "print(test_preds_xgb_2.shape)\n",
    "print(test_preds_EB7_lr.shape)\n",
    "print(test_preds_EB4_lr.shape)\n",
    "# print(test_preds_nn1[0].shape)\n",
    "print(test_preds_nn1.squeeze(1).shape)\n",
    "print(test_preds_nn2.squeeze(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单一模型参数遍历"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.00925957996293372\n",
      "round: 1  \n",
      "round: 2  \n",
      "round: 3  \n",
      "round: 4  \n",
      "round: 5  \n",
      "round: 6  \n",
      "round: 7  \n",
      "round: 8  \n",
      "round: 9  \n",
      "round: 10  \n",
      "round: 11  \n",
      "round: 12  \n",
      "round: 13  \n",
      "round: 14  \n",
      "round: 15  \n",
      "round: 16  \n",
      "round: 17  \n",
      "round: 18  \n",
      "round: 19  \n",
      "round: 20  \n",
      "round: 21  \n",
      "round: 22  \n",
      "round: 23  \n"
     ]
    }
   ],
   "source": [
    "result = 1\n",
    "round = 0\n",
    "for i in [0.1,0.2,0.3,0.4,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59,0.6,0.7,0.8,0.9]:\n",
    "    if log_loss(EB4_y_val, i*val_preds_xgb_2+(1-i)*val_preds_EB4_lr) < result:\n",
    "        result = log_loss(EB4_y_val, i*val_preds_xgb_2+(1-i)*val_preds_EB4_lr)\n",
    "        print(i,result)\n",
    "    round += 1\n",
    "    print(\"round:\",round,\" \",)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2345</td>\n",
       "      <td>0.995380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5378</td>\n",
       "      <td>0.992282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11242</td>\n",
       "      <td>0.995918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3465</td>\n",
       "      <td>0.003456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     label\n",
       "0   2345  0.995380\n",
       "1    170  0.003377\n",
       "2   5378  0.992282\n",
       "3  11242  0.995918\n",
       "4   3465  0.003456"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['id'] = ids\n",
    "subs = np.clip(test_preds_xgb_1,0.0017,0.9974)\n",
    "\n",
    "sample_submission['label'] = subs\n",
    "sample_submission.to_csv('submission_solo5.csv', index=False)\n",
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两种模型组合参数遍历"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost + logistic_regression方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "papermill": {
     "duration": 0.209632,
     "end_time": "2020-10-13T23:14:53.606123",
     "exception": false,
     "start_time": "2020-10-13T23:14:53.396491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275,) (743,)\n",
      "(1836,) (1006,)\n",
      "(2073,) (1126,)\n",
      "(1295,) (755,)\n",
      "(1863,) (1020,)\n",
      "(2102,) (1135,)\n",
      "(1327,) (778,)\n",
      "(1891,) (1029,)\n",
      "(2148,) (1159,)\n",
      "(1372,) (790,)\n",
      "(1923,) (1051,)\n",
      "(2184,) (1173,)\n",
      "(1410,) (807,)\n",
      "(1972,) (1075,)\n",
      "(2226,) (1205,)\n",
      "(1450,) (830,)\n",
      "(2018,) (1109,)\n",
      "(2265,) (1226,)\n",
      "(1473,) (836,)\n",
      "(2037,) (1128,)\n",
      "(2279,) (1236,)\n",
      "(1488,) (854,)\n",
      "(2061,) (1137,)\n",
      "(2308,) (1250,)\n",
      "(1505,) (873,)\n",
      "(2080,) (1151,)\n",
      "(2324,) (1262,)\n",
      "(1537,) (900,)\n",
      "(2114,) (1166,)\n",
      "(2349,) (1278,)\n",
      "(1563,) (913,)\n",
      "(2136,) (1180,)\n",
      "(2372,) (1294,)\n",
      "(1576,) (916,)\n",
      "(2154,) (1181,)\n",
      "(2384,) (1297,)\n",
      "(1594,) (923,)\n",
      "(2172,) (1192,)\n",
      "(2396,) (1308,)\n",
      "(1620,) (931,)\n",
      "(2178,) (1198,)\n",
      "(2404,) (1319,)\n",
      "(1660,) (952,)\n",
      "(2197,) (1212,)\n",
      "(2427,) (1334,)\n",
      "(1691,) (965,)\n",
      "(2217,) (1229,)\n",
      "(2450,) (1350,)\n",
      "(1722,) (985,)\n",
      "(2234,) (1246,)\n",
      "(2468,) (1365,)\n"
     ]
    }
   ],
   "source": [
    "#(xgb1+lr1)+(xgb2+lr2)\n",
    "for alpha in [0.8,0.84,0.88,0.92,0.96,1.0,1.02,1.04,1.06,1.08,1.1,1.11,1.12,1.13,1.15,1.17,1.19]:\n",
    "    sample_submission['id'] = ids\n",
    "    subs = np.clip(alpha*(0.1*test_preds_xgb_1+0.9*test_preds_EB7_lr)+(1-alpha)*(0.1*test_preds_xgb_2+0.9*test_preds_EB4_lr),\n",
    "                   0, \n",
    "                    1)\n",
    "    print(subs[subs < 0.0008].shape,subs[subs > 0.9984].shape)            \n",
    "    print(subs[subs < 0.0010].shape,subs[subs > 0.9982].shape)\n",
    "    print(subs[subs < 0.0011].shape,subs[subs > 0.9981].shape)\n",
    "    # print(subs[subs < 0.0012].shape,subs[subs > 0.9980].shape)\n",
    "    # print(subs[subs < 0.0013].shape,subs[subs > 0.9979].shape)\n",
    "    # print(subs[subs < 0.0014].shape,subs[subs > 0.9978].shape)\n",
    "    # print(subs[subs < 0.0015].shape,subs[subs > 0.9977].shape)\n",
    "    # print(subs[subs < 0.0016].shape,subs[subs > 0.9976].shape)\n",
    "    # print(subs[subs < 0.0017].shape,subs[subs > 0.9975].shape)\n",
    "    # print(subs[subs < 0.0018].shape,subs[subs > 0.9974].shape)\n",
    "    # print(subs[subs < 0.0019].shape,subs[subs > 0.9973].shape)\n",
    "    \n",
    "    subs[subs > 0.9974] = 1\n",
    "    # # subs[subs > 0.9974] = 1\n",
    "    # subs[subs <  0.0008] = 0\n",
    "    subs[subs <  0.0018] = 0\n",
    "    sample_submission['label'] = subs\n",
    "    sample_submission.to_csv('submission_xgb_lr_new_{}.csv'.format(alpha), index=False)\n",
    "    sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost + 神经网络方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "#(xgb1+nn1)+(xgb2+nn2)\n",
    "for alpha in [1.02,1.04,1.06,1.08,1.1,1.12,1.14,1.16]:\n",
    "    # sample_submission['id'] = ids\n",
    "    \n",
    "    subs = np.clip(alpha*(0.5*test_preds_xgb_1+0.5*test_preds_nn1.squeeze(1))+(1-alpha)*(0.5*test_preds_xgb_2+0.5*test_preds_nn2.squeeze(1)),\n",
    "                   0,#0.0018\n",
    "                   1)#0.9974\n",
    "    #0.9980/0.9979\n",
    "    #0.0016/0.0017\n",
    "    print(subs[subs < 0.0012].shape,subs[subs > 0.9980].shape)\n",
    "    print(subs[subs < 0.0013].shape,subs[subs > 0.9979].shape)\n",
    "    print(subs[subs < 0.0014].shape,subs[subs > 0.9978].shape)\n",
    "    print(subs[subs < 0.0015].shape,subs[subs > 0.9977].shape)\n",
    "    print(subs[subs < 0.0016].shape,subs[subs > 0.9976].shape)\n",
    "    print(subs[subs < 0.0017].shape,subs[subs > 0.9975].shape)\n",
    "    print(subs[subs < 0.0018].shape,subs[subs > 0.9974].shape)\n",
    "    print(subs[subs < 0.0019].shape,subs[subs > 0.9973].shape)\n",
    "    # # print(subs.shape)\n",
    "    # subs[subs > 0.9980] = 1\n",
    "    # subs[subs <  0.0016] = 0\n",
    "    \n",
    "#     subs[subs > 0.9980] = 1\n",
    "#     subs[subs <  0.0017] = 0\n",
    "    \n",
    "#     subs[subs > 0.9979] = 1\n",
    "#     subs[subs <  0.0016] = 0\n",
    "    \n",
    "#     subs[subs > 0.9979] = 1\n",
    "#     subs[subs <  0.0017] = 0\n",
    "    sample_submission['label'] = subs\n",
    "    sample_submission.to_csv('submission_xgb_nn_{}.csv'.format(alpha), index=False)\n",
    "    # sample_submission.head()\n",
    "    print(\"success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三种模型组合的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(xgb1+lr1)+(xgb2+lr2)\n",
    "for alpha in [0.5,0.8,1.0,1.06,1.1,1.15,1.17,1.19]:\n",
    "    sample_submission['id'] = ids\n",
    "    subs = np.clip(alpha*(0.4*test_preds_xgb_1+0.3*test_preds_EB7_lr+0.4*test_preds_nn1.squeeze(1))+(1-alpha)*(0.4*test_preds_xgb_2+0.3*test_preds_EB4_lr+test_preds_nn2.squeeze(1)),\n",
    "                   0.0018, \n",
    "                    0.9974)\n",
    "    #测试预测裁减的范围\n",
    "    # print(subs[subs < 0.0008].shape,subs[subs > 0.9984].shape) \n",
    "    # print(subs[subs < 0.0010].shape,subs[subs > 0.9998].shape)\n",
    "    # print(subs[subs < 0.0010].shape,subs[subs > 0.9989].shape)\n",
    "    # print(subs[subs < 0.0010].shape,subs[subs > 0.9987].shape)\n",
    "    # print(subs[subs < 0.0010].shape,subs[subs > 0.9984].shape)\n",
    "    # print(subs[subs < 0.0010].shape,subs[subs > 0.9983].shape)\n",
    "    # print(subs[subs < 0.0010].shape,subs[subs > 0.9982].shape)\n",
    "    # print(subs[subs < 0.0011].shape,subs[subs > 0.9981].shape)\n",
    "    # print(subs[subs < 0.0012].shape,subs[subs > 0.9980].shape)\n",
    "    # print(subs[subs < 0.0013].shape,subs[subs > 0.9979].shape)\n",
    "    # print(subs[subs < 0.0014].shape,subs[subs > 0.9978].shape)\n",
    "    # print(subs[subs < 0.0015].shape,subs[subs > 0.9977].shape)\n",
    "    # print(subs[subs < 0.0016].shape,subs[subs > 0.9976].shape)\n",
    "    # print(subs[subs < 0.0017].shape,subs[subs > 0.9975].shape)\n",
    "    # print(subs[subs < 0.0018].shape,subs[subs > 0.9974].shape)\n",
    "    # print(subs[subs < 0.0019].shape,subs[subs > 0.9973].shape)\n",
    "    \n",
    "#     subs[subs > 0.9984] = 1\n",
    "#     # # subs[subs > 0.9974] = 1\n",
    "#     # subs[subs <  0.0008] = 0\n",
    "    # subs[subs <  0.0010] = 0\n",
    "    sample_submission['label'] = subs\n",
    "    sample_submission.to_csv('submission_xgb_lr_new_{}.csv'.format(alpha), index=False)\n",
    "    sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "duration": 71.154455,
   "end_time": "2020-10-13T23:14:55.650600",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-13T23:13:44.496145",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
